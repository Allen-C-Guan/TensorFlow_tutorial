{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Keras Functional API in TensorFlow\n",
    "函数式的API，给予了Keras更多的flexible，而不是只是通过sequence，去堆叠神经网络了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上节课我们已经了解了如何通过keras.Model()去自定义层了。\n",
    "1. 先建立层结构（kernel结构和数据流结构）\n",
    "2. 放在model里面\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立结构\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name='img')\n",
    "x = layers.Dense(64, activation='relu',name='GOOD')(inputs)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "outputs = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "#放在model里面\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='mnist_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'img:0' shape=(None, 784) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "print(model.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "GOOD (Dense)                 (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#看看什么结构\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "none表示input的维度是不固定的，会随着上一层的input变换而变换。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training evaluation and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0922 22:28:15.973103 4634564032 deprecation.py:323] From /Users/allen/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 2s 38us/sample - loss: 0.3605 - accuracy: 0.8986 - val_loss: 0.1983 - val_accuracy: 0.9424\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 2s 34us/sample - loss: 0.1660 - accuracy: 0.9506 - val_loss: 0.1446 - val_accuracy: 0.9582\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 2s 47us/sample - loss: 0.1208 - accuracy: 0.9640 - val_loss: 0.1214 - val_accuracy: 0.9645\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 0.0962 - accuracy: 0.9712 - val_loss: 0.1170 - val_accuracy: 0.9657\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 2s 35us/sample - loss: 0.0793 - accuracy: 0.9768 - val_loss: 0.1061 - val_accuracy: 0.9698\n",
      "Test loss: 0.09988791370857507\n",
      "Test accuracy: 0.9695\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=5,\n",
    "                    validation_split=0.2)\n",
    "test_scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', test_scores[0])\n",
    "print('Test accuracy:', test_scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用同样的layer来定义多种model\n",
    "如果我们用kera.Model来定义神经网络结构，那数据的流动才是决定神经网络结构的关键。至于怎么写，并不重要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 18,672\n",
      "Trainable params: 18,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#首先我们定义了神经网络结构为，\n",
    "#从encoder_input 到 encoder_output\n",
    "\n",
    "encoder_input = keras.Input(shape=(28, 28, 1), name='img')\n",
    "x = layers.Conv2D(16, 3, activation='relu')(encoder_input)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "mid_break = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(mid_break)\n",
    "x = layers.Conv2D(16, 3, activation='relu')(x)\n",
    "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "\n",
    "#看看从encoder_input 到 encoder_output的结构\n",
    "encoder = keras.Model(encoder_input, encoder_output, name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__我们尝试以mid_break 作为输出，那么神经网络的结构也就被拆分开了。__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 32)          0         \n",
      "=================================================================\n",
      "Total params: 4,800\n",
      "Trainable params: 4,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mid_break= keras.Model(encoder_input, mid_break, name='encoder')\n",
    "mid_break.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__因此，根据上面的分析，只要我们把数据流给他连接上，就可以接着上面的结构继续设计了。__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 4, 4, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 6, 6, 16)          160       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 26, 26, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 28,241\n",
      "Trainable params: 28,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 将encoder_output接着往下写\n",
    "x = layers.Reshape((4, 4, 1))(encoder_output)\n",
    "\n",
    "x = layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation='relu')(x)\n",
    "x = layers.UpSampling2D(3)(x)\n",
    "x = layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
    "decoder_output = layers.Conv2DTranspose(1, 3, activation='relu')(x)\n",
    "\n",
    "#我们规定的input端不变（input端必须有spaceholder），输出端变成了decoder_output，那么网络结构也就跟着写下来了\n",
    "\n",
    "autoencoder = keras.Model(encoder_input, decoder_output, name='autoencoder')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把model当成一个层来使用\n",
    "keras中，我们可以把一个model当成一个层，给input和output，就能把model当层来使用。其他的和keras.Model的用法相同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__先建立一个model1__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 18,672\n",
      "Trainable params: 18,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = keras.Input(shape=(28, 28, 1), name='original_img')\n",
    "x = layers.Conv2D(16, 3, activation='relu')(input1)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(16, 3, activation='relu')(x)\n",
    "output1 = layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "model1 = keras.Model(input1, output1, name='model1')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__在建立一个model2__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model2 (InputLayer)          [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 4, 4, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 6, 6, 16)          160       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 26, 26, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 9,569\n",
      "Trainable params: 9,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input2 = keras.Input(shape=(16,), name='model2')\n",
    "x = layers.Reshape((4, 4, 1))(input2)\n",
    "x = layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation='relu')(x)\n",
    "x = layers.UpSampling2D(3)(x)\n",
    "x = layers.Conv2DTranspose(16, 3, activation='relu')(x)\n",
    "output2 = layers.Conv2DTranspose(1, 3, activation='relu')(x)\n",
    "\n",
    "model2= keras.Model(input2, output2, name='model2')\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__我要把model1和model2 就像一个layer一样使用，建立一个新的model3__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "imag (InputLayer)            [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "model1 (Model)               (None, 16)                18672     \n",
      "_________________________________________________________________\n",
      "model2 (Model)               (None, 28, 28, 1)         9569      \n",
      "=================================================================\n",
      "Total params: 28,241\n",
      "Trainable params: 28,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input3 = keras.Input(shape = (28,28,1), name ='imag')\n",
    "\n",
    "# 利用model1 和 model2 的数据的首位想接，完成两个model的合并。\n",
    "model1_output = model1(input3)\n",
    "model2_output = model2(model1_output)\n",
    "\n",
    "output3 = model2_output\n",
    "\n",
    "model3 = keras.Model(input3, output3, name='model3')\n",
    "\n",
    "model3.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__model1 和 model2 就成立model3 的submodel了，其作用和一个层是一样的。__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型的并联\n",
    "模型的并联是一种最简单的控制数据流的方法了。就是将同样的input输入到三个模型中（三个模型结构可以相同也可以不同），而后将三个模型的输出，拿出来，放到平均层中去取平均。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = keras.Input(shape=(128,))\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(inputs)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "#随便定义三个结构相同的模型\n",
    "model1 = get_model()\n",
    "model2 = get_model()\n",
    "model3 = get_model()\n",
    "\n",
    "\n",
    "# 给出一个input的spaceholder\n",
    "inputs = keras.Input(shape=(128,))\n",
    "\n",
    "# 将这个共同的inputs分别赋值给三个model。得到三个（一维）输出\n",
    "y1 = model1(inputs)\n",
    "y2 = model2(inputs)\n",
    "y3 = model3(inputs)\n",
    "\n",
    "\n",
    "#将这3个输出，作为输入放在average层里取平均\n",
    "outputs = layers.average([y1, y2, y3])\n",
    "\n",
    "#数据的流从inputs，经过三条路，分别进入三个模型中，三个模型的输出最后合并到一起了，\n",
    "# 进入到average 层 而后输出为outputs\n",
    "ensemble_model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Model)                   (None, 1)            129         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 1)            129         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 1)            129         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average (Average)               (None, 1)            0           model[1][0]                      \n",
      "                                                                 model_1[1][0]                    \n",
      "                                                                 model_2[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 387\n",
      "Trainable params: 387\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#看一下他的结构\n",
    "ensemble_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tags = 12  # Number of unique issue tags\n",
    "num_words = 10000  # Size of vocabulary obtained when preprocessing text data\n",
    "num_departments = 4  # Number of departments for predictions\n",
    "\n",
    "title_input = keras.Input(shape=(None,), name='title')  # Variable-length sequence of ints\n",
    "body_input = keras.Input(shape=(None,), name='body')  # Variable-length sequence of ints\n",
    "tags_input = keras.Input(shape=(num_tags,), name='tags')  # Binary vectors of size `num_tags`\n",
    "\n",
    "# Embed each word in the title into a 64-dimensional vector\n",
    "title_features = layers.Embedding(num_words, 64)(title_input)\n",
    "# Embed each word in the text into a 64-dimensional vector\n",
    "body_features = layers.Embedding(num_words, 64)(body_input)\n",
    "\n",
    "# Reduce sequence of embedded words in the title into a single 128-dimensional vector\n",
    "title_features = layers.LSTM(128)(title_features)\n",
    "# Reduce sequence of embedded words in the body into a single 32-dimensional vector\n",
    "body_features = layers.LSTM(32)(body_features)\n",
    "\n",
    "# Merge all available features into a single large vector via concatenation\n",
    "x = layers.concatenate([title_features, body_features, tags_input])\n",
    "\n",
    "# Stick a logistic regression for priority prediction on top of the features\n",
    "priority_pred = layers.Dense(1, activation='sigmoid', name='priority')(x)\n",
    "# Stick a department classifier on top of the features\n",
    "department_pred = layers.Dense(num_departments, activation='softmax', name='department')(x)\n",
    "\n",
    "# Instantiate an end-to-end model predicting both priority and department\n",
    "model = keras.Model(inputs=[title_input, body_input, tags_input],\n",
    "                    outputs=[priority_pred, department_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, 'multi_input_and_output_model.png', show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
