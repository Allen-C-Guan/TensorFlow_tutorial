{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras的总览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model与layer的简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stack of layers by Sequential\n",
    "利用layer的堆叠来建立神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Add another:\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Add a softmax layer with 10 output units:\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### layer的功能介绍\n",
    "layer自身也有很多选项，例如， activation，kernel_initializer, regularizer等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sigmoid layer:\n",
    "layers.Dense(64, activation='sigmoid')\n",
    "# Or:\n",
    "layers.Dense(64, activation=tf.keras.activations.sigmoid)\n",
    "\n",
    "# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
    "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "\n",
    "# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\n",
    "layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "# A linear layer with a kernel initialized to a random orthogonal matrix:\n",
    "layers.Dense(64, kernel_initializer='orthogonal')\n",
    "\n",
    "# A linear layer with a bias vector initialized to 2.0s:\n",
    "layers.Dense(64, bias_initializer=tf.keras.initializers.Constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train and evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 堆叠模型\n",
    "建立模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "# Add another:\n",
    "layers.Dense(64, activation='relu'),\n",
    "# Add a softmax layer with 10 output units:\n",
    "layers.Dense(10, activation='softmax')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编译模型\n",
    "选择optimizer，loss function等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 其他的一些编译方法"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Configure a model for mean-squared error regression.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "              loss='mse',       # mean squared error\n",
    "              metrics=['mae'])  # mean absolute error\n",
    "\n",
    "# Configure a model for categorical classification.\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train ( model.fit ( ) )\n",
    "建立并编译过后的模型就可以把数据和label放进去训练了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__最基本的train的方法__\n",
    "1. data和label\n",
    "2. 重复dataset的次数， epochs\n",
    "3. 每次训练的数据集， batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0922 16:38:42.656823 4485526976 deprecation.py:323] From /Users/allen/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 391us/sample - loss: 11.5482 - accuracy: 0.0950\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 79us/sample - loss: 11.5211 - accuracy: 0.0900\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 74us/sample - loss: 11.5200 - accuracy: 0.0970\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 79us/sample - loss: 11.5193 - accuracy: 0.1030\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 81us/sample - loss: 11.5187 - accuracy: 0.0990\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 73us/sample - loss: 11.5178 - accuracy: 0.1160\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 74us/sample - loss: 11.5184 - accuracy: 0.1060\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 76us/sample - loss: 11.5173 - accuracy: 0.1060\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 88us/sample - loss: 11.5173 - accuracy: 0.1190\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 88us/sample - loss: 11.5166 - accuracy: 0.1150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x6329f2940>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 有validation的训练\n",
    "validation 的作用是利用test_set 在训练的过程中就验证其预测的能力。\n",
    "\n",
    "注意: 不管是acc 还是 loss，都是train_set的准确度的评价，和预测无关。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 215us/sample - loss: 11.3635 - accuracy: 0.0980 - val_loss: 11.4229 - val_accuracy: 0.0900\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 74us/sample - loss: 11.3610 - accuracy: 0.0840 - val_loss: 11.4232 - val_accuracy: 0.1100\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 78us/sample - loss: 11.3608 - accuracy: 0.1070 - val_loss: 11.4223 - val_accuracy: 0.1000\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 11.3615 - accuracy: 0.1100 - val_loss: 11.4221 - val_accuracy: 0.1000\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 11.3614 - accuracy: 0.1120 - val_loss: 11.4222 - val_accuracy: 0.1000\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 85us/sample - loss: 11.3607 - accuracy: 0.1090 - val_loss: 11.4224 - val_accuracy: 0.1000\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 11.3606 - accuracy: 0.1090 - val_loss: 11.4213 - val_accuracy: 0.0800\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 11.3606 - accuracy: 0.0960 - val_loss: 11.4214 - val_accuracy: 0.0800\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 115us/sample - loss: 11.3606 - accuracy: 0.1060 - val_loss: 11.4222 - val_accuracy: 0.1000\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 11.3609 - accuracy: 0.1020 - val_loss: 11.4216 - val_accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x10d5faa90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "val_data = np.random.random((100, 32))\n",
    "val_labels = np.random.random((100, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用tf.Dataset的数据作为fit的数据的方法\n",
    "我们既可以直接把初始的数据直接放在fit里面。也可以把Dataset类型的迭代器产生的数据放在fit里面。效果是一样的。而bitch size会以dataset的迭代器的bitch所决定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0922 16:53:28.286640 4485526976 training_utils.py:1436] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 11.3548 - accuracy: 0.1110\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 11.3551 - accuracy: 0.1080\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 11.3550 - accuracy: 0.1080\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 11.3550 - accuracy: 0.1080\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 11.3550 - accuracy: 0.1080\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 11.3550 - accuracy: 0.1080\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 11.3550 - accuracy: 0.1080\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 11.3550 - accuracy: 0.1080\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 11.3550 - accuracy: 0.1080\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 11.3549 - accuracy: 0.1080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x63344d240>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiates a toy dataset instance:\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)\n",
    "\n",
    "model.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation也可以是Dataset类型的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0922 16:55:12.652235 4485526976 training_utils.py:1436] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 11.3549 - accuracy: 0.1080 - val_loss: 12.0197 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 11.3549 - accuracy: 0.1080 - val_loss: 12.0197 - val_accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 11.3549 - accuracy: 0.1080 - val_loss: 12.0197 - val_accuracy: 0.1000\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 11.3549 - accuracy: 0.1080 - val_loss: 12.0197 - val_accuracy: 0.1000\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 11.3549 - accuracy: 0.1080 - val_loss: 12.0197 - val_accuracy: 0.1000\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 11.3549 - accuracy: 0.1080 - val_loss: 12.0197 - val_accuracy: 0.1000\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 11.3549 - accuracy: 0.1080 - val_loss: 12.0197 - val_accuracy: 0.1000\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 11.3549 - accuracy: 0.1080 - val_loss: 12.0197 - val_accuracy: 0.1000\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 11.3549 - accuracy: 0.1080 - val_loss: 12.0197 - val_accuracy: 0.1000\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 11.3549 - accuracy: 0.1080 - val_loss: 12.0197 - val_accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x63344de80>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "\n",
    "model.fit(dataset, epochs=10,\n",
    "          validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate \n",
    "使用model.evaluate就可以轻松的完成评价。\n",
    "\n",
    "evaluate()接受的数据同样，既可以是原始数据，又可以是Dateset的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 114us/sample - loss: 11.4411 - accuracy: 0.1020\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 11.4055 - accuracy: 0.1020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.405467629432678, 0.102]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With Numpy arrays\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "model.evaluate(data, labels, batch_size=32)\n",
    "\n",
    "# With a Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)\n",
    "\n",
    "model.evaluate(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction\n",
    "model.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(data, batch_size=32)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build complex models (keras的自定义）\n",
    "1. 利用变量在神经网络层之间的传递，搭建神经网络的结构\n",
    "2. 将搭建的层放在keras.Model里面\n",
    "3. 一旦model完成，那么一切和之前将毫无差别。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 搭建结构\n",
    "结构的搭建主要是利用变量的相互赋值来完成的！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input层\n",
    "\n",
    "#用keras.Input 类实例化一个inputs，其返回的是 相应个数的spaceholder,留给以后的input\n",
    "inputs = tf.keras.Input(shape=(32,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden layer\n",
    "\n",
    "#利用变量的赋值来传递数据流。\n",
    "x = layers.Dense(64,activation = 'relu')(inputs)\n",
    "x = layers.Dense(64,activation = 'relu')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出层\n",
    "\n",
    "predictions = layers.Dense(10,activation = 'softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__建立模型__\\\n",
    "利用keras.Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs = inputs, outputs = predictions)#建立model后，与之前就完全相同了\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.RMSprop(0.001),\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__fit__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 383us/sample - loss: 11.4793 - accuracy: 0.0950\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 102us/sample - loss: 11.4474 - accuracy: 0.1050\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 83us/sample - loss: 11.4408 - accuracy: 0.1140\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 11.4360 - accuracy: 0.1140\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 78us/sample - loss: 11.4324 - accuracy: 0.1130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x6335c6c50>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完全自定义的Keras model\n",
    "我们可以利用对keras.Model的override来完成自定义model的方法！ 这种方法给予了更多的flexible。\n",
    "\n",
    "Model主要是由两部分函数组成：\n",
    "1. \\__init__：在实例化的过程中就被定义好了且不能改的部分，主要包括：\n",
    "    1. 输出的维度\n",
    "    2. 层的结构（只是结构，没有数据的流通和衔接）\n",
    "    \n",
    "\n",
    "2. call：在调用的时候才运行，主要完成的任务：\n",
    "    1. 读取到输入。\n",
    "    2. 将层的结构都连接起来（通过变量的的传递）\n",
    "    3. 返回神经网络输出的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    #定义model的初始化\n",
    "    \n",
    "    def __init__(self, num_classes =10):\n",
    "        super(MyModel,self).__init__(name = 'my_model')#继承父类的全部init\n",
    "        self.num_classes = num_classes#实例变量：输出的维度\n",
    "        \n",
    "        #define layers\n",
    "        self.dense_1 = layers.Dense(32,activation='relu')\n",
    "        self.dense_2 = layers.Dense(num_classes,activation = 'sigmoid')\n",
    "        \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        #这个函数利用在init函数中已经定义好的结构来用来定义数据流的（通过参数的赋值）\n",
    "        \n",
    "        x = self.dense_1(inputs)\n",
    "        x = self.dense_2(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 实例化自己建立的model\n",
    "从这之后就没有区别了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#编译\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 262us/sample - loss: 11.5392 - accuracy: 0.0950\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 109us/sample - loss: 11.4616 - accuracy: 0.0990\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 11.4546 - accuracy: 0.1100\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 78us/sample - loss: 11.4499 - accuracy: 0.1080\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 82us/sample - loss: 11.4456 - accuracy: 0.1110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x633be8c88>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义层\n",
    "之前我们通过自定义keras.Model()中的\\__init__函数和call，完成了在model层面的自定义。在该部分中，我们将在layer的层面上实现自定义。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer的自定义主要由4个部分组成分别是：\n",
    "1. \\__init__:\\\n",
    "    其主要负责初始化一些在定值且不会改变的内容（output 的维度）\n",
    "    \n",
    "    \n",
    "2. build()\\\n",
    "    一般用于定义layer的结构。因为layer需要有一定的flexiability，(input的维度最好不要是个定值，不然该层layer只能接收固定维度的input。\n",
    "    \n",
    "    这里要记得layer(kernel)，本质上是矩阵计算！！！！！因此你要定义的就是矩阵的类型即可！！\n",
    "    \n",
    "\n",
    "3. call()\\\n",
    "    一般用于定义kernel和input之间的计算关系。返回值是计算结果。\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "add_weight() 用于设置层的结构。\n",
    "\n",
    "add_weight(\n",
    "    name=None,\n",
    "    shape=None,\n",
    "    dtype=None,\n",
    "    initializer=None,\n",
    "    regularizer=None,\n",
    "    trainable=None,      #选择该层是否需要被训练，如果不训练就不会改变该层的权值。\n",
    "    constraint=None,\n",
    "    partitioner=None,\n",
    "    use_resource=None,\n",
    "    synchronization=tf.VariableSynchronization.AUTO,\n",
    "    aggregation=tf.VariableAggregation.NONE,\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayer(layers.Layer):\n",
    "    def __init__(self,output_dim,**kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(MyLayer,self).__init__(**kwargs)\n",
    "    \n",
    "    #定义该层的结构\n",
    "    #定义kernel的结构为 input的第二维度*output维度的变量矩阵。\n",
    "    \n",
    "    def build(self,input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                  shape=(input_shape[1], self.output_dim),\n",
    "                                      #定义矩阵的维度。\n",
    "                                  initializer='uniform',\n",
    "                                  trainable=True)\n",
    "    ##定义kernel和input的计算关系\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.kernel)\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super(MyLayer, self).get_config()\n",
    "        base_config['output_dim'] = self.output_dim\n",
    "        return base_config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "                                    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们这就完成了一个layer的定义，这个layer将和你用到的keras的layer完全一样，可以放在keras里面直接用，也可以放在Model，定义一个自己的model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用自定义layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 228us/sample - loss: 11.4464 - accuracy: 0.0890\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 11.4415 - accuracy: 0.0930\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 11.4395 - accuracy: 0.0990\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 11.4384 - accuracy: 0.1090\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 82us/sample - loss: 11.4369 - accuracy: 0.1020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x6338d4a58>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    MyLayer(10),#output 维度为10，\n",
    "    layers.Activation('softmax')\n",
    "    ])\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trains for 5 epochs.\n",
    "model.fit(data, labels, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras model的保存与重载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 478us/sample - loss: 11.4491 - accuracy: 0.1020\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 71us/sample - loss: 11.4409 - accuracy: 0.1010\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 91us/sample - loss: 11.4393 - accuracy: 0.1060\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 73us/sample - loss: 11.4389 - accuracy: 0.1120\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 79us/sample - loss: 11.4385 - accuracy: 0.0990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x6344ab5c0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  layers.Dense(10, activation='softmax', input_shape=(32,)),\n",
    "  layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(data, labels, batch_size=32, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#一句话，就保存了全部的model部分。\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the exact same model, including weights and optimizer.\n",
    "\n",
    "model = tf.keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
