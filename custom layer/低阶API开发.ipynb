{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定制化训练：基础\n",
    "这是所有优化问题的基础！ 建立模型，寻找模型的参数。\\\n",
    "方法为：利用对loss function中的模型参数求导数，去定梯度。迭代下降。\n",
    "\n",
    "实现为：\n",
    "1. model主要是用来定义数学模型的（用线性还是多项式来拟合模型），一个callable的class，__call__中定义了函数的参数模型。\n",
    "2. loss function，定义了(pred(model) - true)\n",
    "3. optimizer实现两个功能。\n",
    "    1. 对参数求导：求的是loss function对param的导数\n",
    "    2. 迭代更改参数：param_new = old_param + （-梯度）*步长"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # Colab only\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      " [2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]], shape=(10, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 使用 python 状态\n",
    "x = tf.zeros([10, 10])\n",
    "# 等价于 x = x + 2, 不改变原本 x 的值\n",
    "x +=2  \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variable\n",
    "variable是一个object,而这个obj不但存储着数值，而且自身就有一些method，可以直接对里面存储对数值做一些操作。\\\n",
    "可以理解为是一个封装了的数值。\n",
    "\n",
    "于constant不同的是，constant需要手动watch，而variable会被GradientTape自动跟踪。我们不需要手动watch variable.\\\n",
    "当计算梯度时，会自动跟踪使用变量的计算过程。用变量来表示向量时，TensorFlow 会默认使用稀疏更新，这样可以带来计算和存储高效性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tf.Variable(1.0)\n",
    "assert v.numpy() == 1.0\n",
    "#当我们给variable初始化的时候，可以给变量赋值\n",
    "\n",
    "\n",
    "\n",
    "# 重新赋值\n",
    "v.assign(3.0)\n",
    "assert v.numpy() == 3.0\n",
    "#我们利用assign函数对变量重新赋值。（这就是obj和primite的区别）\n",
    "\n",
    "# 在 TensorFlow 操作中使用 `v`，比如  tf.square() 和重新赋值\n",
    "v.assign(tf.square(v))\n",
    "assert v.numpy() == 9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立一个线性模型。\n",
    "我们使用低级API（Tensor，Variable，GradientTape）来自定义一个线性模型。\n",
    "\n",
    "常用的步骤如下：\n",
    "1. 定义模型\n",
    "2. 定义loss function\n",
    "3. 获取dataset\n",
    "4. 通过dataset，利用optimizer来调整变量的值来优化loss function。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义模型\n",
    "我们可以把模型封装在class里面，从而让代码更加的模块化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初值 model(x) = 5*x + 0\n",
    "class Model(object):\n",
    "    def __init__(self):\n",
    "        self.W = tf.Variable(5.0)  #都直接定义成variable的形式，让微分器自动的去追踪\n",
    "        self.b = tf.Variable(0.0)\n",
    "        \n",
    "    def __call__(self,x):          #这是一个可以被call的class\n",
    "        return self.W*x+self.b\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尝试一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()##实例化调用的是init函数\n",
    "model(3).numpy()#call的时候执行的是__call__函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "建立函数：loss(model_output,label)\\\n",
    "在tensorflow里面reduce前缀都表示降维度计算，而默认的维度是降为一维度。也可以选择按行或者按列降低维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(predicted_y,desired_y):\n",
    "    return tf.reduce_mean(tf.square(predicted_y - desired_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "试一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(3,4).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建训练的dataset（with noise）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练函数方程是 f(x) = 3*x+2\n",
    "TRUE_W = 3.0\n",
    "TRUE_b = 2.0\n",
    "NUM_EXAMPLES = 1000\n",
    "\n",
    "inputs  = tf.random.normal(shape=[NUM_EXAMPLES])#x\n",
    "noise   = tf.random.normal(shape=[NUM_EXAMPLES])#noise\n",
    "outputs = inputs * TRUE_W + TRUE_b + noise #3*x+b+noise\n",
    "\n",
    "#这里由于用完全相同的函数随机生成的，noise的平均值并不一定比input的平均值小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: \n",
      "9.239105\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(inputs, outputs, c='b')\n",
    "plt.scatter(inputs, model(inputs), c='r')\n",
    "plt.show()\n",
    "\n",
    "print('Current loss: '),\n",
    "print(loss(model(inputs), outputs).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义optimizer\n",
    "optimizer的作用是，每次使用optimizer一次，都会完成一步的优化。\n",
    "\n",
    "optimizer的设置可以直接利用tf.train.Optimizer来实现，里面有大量已经写好的optimizer。这里我们先自己写。\n",
    "\n",
    "写梯度下降法的思想是：\n",
    "1. 在微分器中建立loss function与变量weight和bias之间的关系，常量是input，output.\\\n",
    "    具体方程为：new_loss = loss(model(input)，real_label)\n",
    "    \n",
    "    \n",
    "2. 调用微分器求出loss function的偏导数。\n",
    "\n",
    "\n",
    "3. 更改model中变量的值。\\\n",
    "    new_value = value - step_length * dx\n",
    "    \n",
    "    \n",
    "其思路是：利用用gradientTape来求loss function(model输出于真实输出的差值) 对 model(数学模型）中的系数的梯度。 而后用梯度作为方向，取一个步长来下降。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer(model,inputs,outputs,learning_rate):\n",
    "    with tf.GradientTape() as t:\n",
    "        current_loss = loss(model(inputs),outputs)\n",
    "        #知识点：我们通过函数的调用即model()，可以在允许在微分器里面调入跳出\n",
    "        #因此，这里lossfunction是关于variable.W,与variable.b的函数。\n",
    "        #input和output不会被追踪，因为他们是constant（primate）类型\n",
    "        #tape只最终variable和watch的对象。\n",
    "        \n",
    "    dw,db = t.gradient(current_loss,[model.W,model.b])\n",
    "    #又是一个知识点，正如上面所说，微分器会自动记录所有参与到计算的variable的微分情况\n",
    "    #这里可以用list的形式来分别求导并分别赋值。\n",
    "    \n",
    "    model.W.assign_sub(learning_rate*dw)\n",
    "    model.b.assign_sub(learning_rate*db)\n",
    "    #知识点again！tf.variable.assign_sub\n",
    "    #var.assign_sub(delta)等于 var = var - delta!\n",
    "    #而当delta = dw * step_length的时候，就是优化算法了！！wonderful！！！\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 迭代训练\n",
    "迭代训练的实现是基于不断的调用optimizer。每调用一次optimizer，梯度下降法下降一个步长。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0: W=5.00 b=0.00, loss=9.23911\n",
      "Epoch  1: W=4.17 b=0.80, loss=3.89950\n",
      "Epoch  2: W=3.67 b=1.28, loss=2.02397\n",
      "Epoch  3: W=3.37 b=1.56, loss=1.36515\n",
      "Epoch  4: W=3.20 b=1.72, loss=1.13371\n",
      "Epoch  5: W=3.09 b=1.82, loss=1.05240\n",
      "Epoch  6: W=3.03 b=1.88, loss=1.02383\n",
      "Epoch  7: W=2.99 b=1.91, loss=1.01379\n",
      "Epoch  8: W=2.97 b=1.93, loss=1.01026\n",
      "Epoch  9: W=2.96 b=1.94, loss=1.00902\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Model()\n",
    "\n",
    "# 收集 W 和 b 的历史数值，用于显示\n",
    "Ws, bs = [], []\n",
    "epochs = range(10)\n",
    "for epoch in epochs:\n",
    "    ##作图所用\n",
    "    Ws.append(model.W.numpy())\n",
    "    bs.append(model.b.numpy())\n",
    "    current_loss = loss(model(inputs), outputs)\n",
    "    ##作图记录点\n",
    "    \n",
    "   \n",
    "    ##真正的训练只需要这一句话，调用optimizor就够了。\n",
    "    optimizer(model, inputs, outputs, learning_rate=0.2)\n",
    "    \n",
    "    \n",
    "    print('Epoch %2d: W=%1.2f b=%1.2f, loss=%2.5f' %\n",
    "        (epoch, Ws[-1], bs[-1], current_loss))\n",
    "\n",
    "# 显示所有\n",
    "plt.plot(epochs, Ws, 'r',\n",
    "         epochs, bs, 'b')\n",
    "plt.plot([TRUE_W] * len(epochs), 'r--',\n",
    "         [TRUE_b] * len(epochs), 'b--')\n",
    "plt.legend(['W', 'b', 'true W', 'true_b'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
