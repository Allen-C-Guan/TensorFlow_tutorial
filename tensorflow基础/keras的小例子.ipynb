{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "## tf. keras \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "## check the version of tensorflow and keras\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0807 20:51:48.032514 4685788608 deprecation.py:506] From /Users/allen/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "## keras.Sequential 堆叠神经层\n",
    "model=tf.keras.Sequential()\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##compile\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 149us/sample - loss: 203.7780 - val_loss: 147.0841\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 170.2641 - val_loss: 165.0391\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 173.8624 - val_loss: 234.5787\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 110us/sample - loss: 246.4807 - val_loss: 216.5237\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 278.9291 - val_loss: 278.4398\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 310.3204 - val_loss: 410.2523\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 307.9985 - val_loss: 346.0824\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 288.2876 - val_loss: 237.3504\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 104us/sample - loss: 364.0969 - val_loss: 374.9807\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 130us/sample - loss: 390.4729 - val_loss: 353.4474\n"
     ]
    }
   ],
   "source": [
    "##fit\n",
    "import numpy as np\n",
    "##generate data\n",
    "data=np.random.random((1000,32))\n",
    "labels=np.random.random((1000,10))\n",
    "history=model.fit(data, labels, epochs=10, batch_size=32,\n",
    "          validation_data=(data, labels))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
